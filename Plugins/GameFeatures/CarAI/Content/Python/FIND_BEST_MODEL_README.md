# Bestes Modell finden - Script-Anleitung

Das Script `find_best_model.py` analysiert alle trainierten Modelle und identifiziert das beste basierend auf verschiedenen Metriken.

## Verwendung

### Basis-Verwendung (nur Loss-Analyse)

```powershell
cd "C:\Users\YvesT\Documents\Unreal Projects\StuntCarRacer\Plugins\GameFeatures\CarAI\Content\Python"
python find_best_model.py
```

Das Script:
- Findet alle `model_epoch_*.pt` Dateien im Models-Verzeichnis
- Analysiert die Loss-Werte aus der Training History
- Erstellt Rankings basierend auf verschiedenen Kriterien
- Gibt eine Empfehlung aus

### Mit Evaluation auf Test-Daten

```powershell
python find_best_model.py --evaluate
```

Das Script:
- F√ºhrt zus√§tzlich eine Evaluation auf Test-Daten durch
- Verwendet 20% der Export-Daten als Test-Set (standardm√§√üig)
- Berechnet Value Error und andere Metriken

### Optionen

```powershell
python find_best_model.py --help
```

**Verf√ºgbare Optionen:**
- `--model-dir PATH`: Verzeichnis mit Modellen (Standard: `Saved/Training/Models`)
- `--export-dir PATH`: Verzeichnis mit Export-Daten (Standard: `Saved/Training/Exports`)
- `--evaluate`: F√ºhre Evaluation auf Test-Daten durch
- `--test-split FLOAT`: Anteil f√ºr Test-Set (0.0-1.0, Standard: 0.2)

## Was wird analysiert?

### 1. Loss-Werte
- **Value Loss Final**: Finaler Value Loss (niedriger = besser)
- **Value Loss Min**: Minimaler Value Loss w√§hrend Training
- **Value Loss Mean**: Durchschnittlicher Value Loss
- **Policy Loss Final**: Finaler Policy Loss
- **Total Loss**: Kombinierter Loss

### 2. Trends
- **Sinkend** üìâ: Loss sinkt kontinuierlich (gut!)
- **Stabil** ‚û°Ô∏è: Loss bleibt konstant
- **Steigend** üìà: Loss steigt (Overfitting m√∂glich!)

### 3. Rankings

Das Script erstellt mehrere Rankings:

1. **Value Loss Final**: Niedrigster finaler Value Loss
2. **Value Loss Min**: Niedrigster minimaler Value Loss
3. **Total Loss Final**: Niedrigster finaler Total Loss
4. **Trend**: Bestes Trend-Verhalten
5. **Kombiniert**: Gewichteter Score aus allen Metriken

## Ausgabe

### Konsolen-Ausgabe

```
================================================================================
MODELL-ANALYSE: Beste Generation finden
================================================================================

üìä Gefundene Modelle: 10
--------------------------------------------------------------------------------

1. model_epoch_1.pt (Epoche 1)
   Value Loss (final): 1.234567
   Value Loss (min):   1.123456
   Trend: üìâ Sinkend (gut!)

...

üèÜ RANKINGS
================================================================================

ü•á Bestes Modell (kombinierter Score):
   model_epoch_8.pt (Epoche 8)
   Score: 0.456789 (niedriger = besser)

üí° EMPFEHLUNG
================================================================================

‚úÖ Empfohlenes Modell: model_epoch_8.pt
   Epoche: 8

üìù N√§chste Schritte:
   1. Exportiere Modell zu JSON:
      python export_model_for_unreal.py "...\model_epoch_8.pt" "...\model_epoch_8.json"
   2. Lade Modell in Unreal Editor Widget
   3. Teste das Modell im Spiel
```

### JSON-Ausgabe

Das Script speichert auch eine detaillierte Analyse als JSON:

```
Saved/Training/Models/model_analysis.json
```

Enth√§lt:
- Alle Metriken f√ºr jedes Modell
- Rankings (Top 5 f√ºr jede Kategorie)
- Evaluation-Ergebnisse (falls `--evaluate` verwendet)

## Interpretation der Ergebnisse

### Bestes Modell finden

**Standard-Empfehlung:**
- Das Script empfiehlt das Modell mit dem **niedrigsten kombinierten Score**
- Dieser Score ber√ºcksichtigt:
  - Value Loss Final (40% Gewicht)
  - Value Loss Min (30% Gewicht)
  - Trend (30% Gewicht)

### Overfitting erkennen

**Warnzeichen:**
- Value Loss steigt in sp√§teren Epochen (Trend = üìà)
- Script warnt: "‚ö†Ô∏è WARNUNG: Value Loss steigt (Overfitting m√∂glich!)"

**L√∂sung:**
- Teste eine fr√ºhere Epoche (z.B. `epoch_7` statt `epoch_10`)
- Oder verwende das Modell mit dem niedrigsten Value Loss Min

### Beispiel-Interpretation

```
Epoche 1: Value Loss = 1.5  (hoch, normal am Anfang)
Epoche 5: Value Loss = 0.8  (sinkt, gut!)
Epoche 8: Value Loss = 0.5  (niedrigster Wert!)
Epoche 10: Value Loss = 0.7 (steigt wieder, Overfitting!)
```

**Empfehlung:** Epoche 8 (niedrigster Value Loss)

## H√§ufige Fragen

### Q: Warum wird nicht immer die letzte Epoche empfohlen?

**A:** Sp√§tere Epochen k√∂nnen **Overfitting** zeigen (Loss steigt wieder). Das Script erkennt das automatisch und empfiehlt die beste Epoche.

### Q: Was ist der Unterschied zwischen "Value Loss Final" und "Value Loss Min"?

**A:**
- **Final**: Der Loss am Ende der Epoche (kann h√∂her sein durch Overfitting)
- **Min**: Der niedrigste Loss w√§hrend der Epoche (beste Performance)

### Q: Soll ich `--evaluate` verwenden?

**A:** Optional, aber empfohlen! Die Evaluation testet die Modelle auf ungesehenen Daten und gibt zus√§tzliche Metriken.

### Q: Was mache ich mit der Empfehlung?

**A:**
1. Exportiere das empfohlene Modell zu JSON (siehe Ausgabe)
2. Lade es in Unreal Editor Widget
3. Teste es im Spiel
4. Falls nicht zufrieden: Teste die Top 3 Modelle manuell

## Troubleshooting

### "Keine Modelle gefunden"

**Ursache:** Keine `model_epoch_*.pt` Dateien im Models-Verzeichnis

**L√∂sung:**
- Stelle sicher, dass `train_pytorch.py` erfolgreich gelaufen ist
- Pr√ºfe Verzeichnis: `Saved/Training/Models/`

### "Fehler beim Laden von model_epoch_X.pt"

**Ursache:** Besch√§digte Modell-Datei

**L√∂sung:**
- √úberspringe diese Datei (Script macht das automatisch)
- Trainiere das Modell neu

### "Keine Export-Dateien gefunden f√ºr Evaluation"

**Ursache:** Keine Rollout-Dateien im Export-Verzeichnis

**L√∂sung:**
- Das ist OK - Evaluation ist optional
- Script funktioniert auch ohne Evaluation (nur Loss-Analyse)

## Tipps

1. **Regelm√§√üig ausf√ºhren:** Nach jedem Training das Script ausf√ºhren, um das beste Modell zu finden

2. **Mehrere Metriken pr√ºfen:** Nicht nur auf "Value Loss Final" schauen - auch "Trend" und "Min" ber√ºcksichtigen

3. **Manuell testen:** Die Top 3 Modelle manuell in Unreal testen - manchmal f√ºhlt sich ein Modell besser an, auch wenn die Metriken anders sind

4. **Evaluation verwenden:** `--evaluate` gibt zus√§tzliche Sicherheit, dass das Modell auch auf neuen Daten gut funktioniert

---

Viel Erfolg beim Finden des besten Modells! üöóü§ñ
